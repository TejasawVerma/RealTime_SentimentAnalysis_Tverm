{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5025ec40-464d-4a54-ac7a-ae6cdf92e946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Install Azure AI Text Analytics SDK\n",
    "%pip install azure-ai-textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c2abe1-2a84-4448-8ec3-3603dde86ae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Imports ------------------\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89d495ec-c3dd-4e84-baf5-51071078c0fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Storage Config ------------------\n",
    "storage_account_name = \"twdrprdcacentral\"\n",
    "container_name = \"twitterdatabase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "408e0fb7-262e-47c4-a631-47cd0889825f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Read All Tweets ------------------\n",
    "path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/*/*/*/\"\n",
    "df = spark.read.parquet(path)\n",
    "pandas_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c5b482d-671b-4eac-b203-65c081e540f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Azure Language Config ------------------\n",
    "endpoint = \"\"\n",
    "key = \"\"\n",
    "credential = AzureKeyCredential(key)\n",
    "client = TextAnalyticsClient(endpoint=endpoint, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd7bddae-a2bb-4e10-bfc6-04f6f7cd8b6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Liberal and Conservative Keywords ------------------\n",
    "liberal_keywords = [\n",
    "    \"#CanadaElectionS2025\", \"liberal party\", \"liberals\", \"lpc\", \"justin trudeau\", \"trudeau\", \"mark carney\", \"carney\", \"#teamtrudeau\", \"#trudeaumustgo\"\n",
    "]\n",
    "conservative_keywords = [\n",
    "    \"conservative party\", \"conservatives\", \"cpc\", \"pierre poilievre\", \"poilievre\", \"#pierrepoilievre\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37c782ca-1658-4fc2-bb6b-478e533f29d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Analyze Sentiment with Opinion Mining and Fallback ------------------\n",
    "def analyze_party_sentiment(documents):\n",
    "    results = []\n",
    "    batch_size = 10\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i+batch_size]\n",
    "        response = client.analyze_sentiment(documents=batch, show_opinion_mining=True)\n",
    "        \n",
    "        for j, doc in enumerate(response):\n",
    "            liberal_sentiment = None\n",
    "            conservative_sentiment = None\n",
    "            liberal_found = False\n",
    "            conservative_found = False\n",
    "\n",
    "            if not doc.is_error:\n",
    "                # Try mined opinions first\n",
    "                for sentence in doc.sentences:\n",
    "                    for opinion in sentence.mined_opinions:\n",
    "                        target = opinion.target.text.lower()\n",
    "                        sentiment = opinion.target.sentiment\n",
    "                        print(sentence)\n",
    "                        #print(f\"Target: {target}, Sentiment: {sentiment}\")\n",
    "                        \n",
    "                        if any(keyword in target for keyword in liberal_keywords):\n",
    "                            liberal_sentiment = sentiment\n",
    "                            liberal_found = True\n",
    "                        if any(keyword in target for keyword in conservative_keywords):\n",
    "                            conservative_sentiment = sentiment\n",
    "                            conservative_found = True\n",
    "\n",
    "                # Fallback to overall document sentiment if necessary\n",
    "                original_text = batch[j]['text'].lower()\n",
    "\n",
    "                if not liberal_found:\n",
    "                    if any(keyword in original_text for keyword in liberal_keywords):\n",
    "                        liberal_sentiment = doc.sentiment\n",
    "\n",
    "                if not conservative_found:\n",
    "                    if any(keyword in original_text for keyword in conservative_keywords):\n",
    "                        conservative_sentiment = doc.sentiment\n",
    "\n",
    "                results.append({\n",
    "                    \"id\": doc.id,\n",
    "                    \"liberal_sentiment\": liberal_sentiment,\n",
    "                    \"conservative_sentiment\": conservative_sentiment\n",
    "                })\n",
    "            else:\n",
    "                results.append({\n",
    "                    \"id\": doc.id,\n",
    "                    \"liberal_sentiment\": \"error\",\n",
    "                    \"conservative_sentiment\": \"error\"\n",
    "                })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4155a4a4-7b1d-4b02-9ded-a32e96972d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Prepare Documents ------------------\n",
    "texts = [{\"id\": str(i), \"text\": text} for i, text in enumerate(pandas_df['text'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "379d8673-f50b-4920-9cb6-052d9bab8e69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Run Sentiment Analysis ------------------\n",
    "party_sentiment_results = analyze_party_sentiment(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02bdd561-7940-468f-a18d-6a866f64d7fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Merge with Original Tweets ------------------\n",
    "party_sentiment_df = pd.DataFrame(party_sentiment_results)\n",
    "pandas_df = pandas_df.reset_index()\n",
    "pandas_df['id'] = pandas_df['index'].astype(str)\n",
    "party_sentiment_df['id'] = party_sentiment_df['id'].astype(str)\n",
    "final_df = pd.merge(pandas_df, party_sentiment_df, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0caade9c-3f15-4eb0-aeac-b67dab16cc08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Final Refinement ------------------\n",
    "# Only keep author_id, created_at, liberal_sentiment, conservative_sentiment\n",
    "# Convert created_at to datetime\n",
    "# Sort by author_id and latest created_at\n",
    "# Keep latest tweet per author\n",
    "# Reset index for clean output\n",
    "refined_df = final_df[['author_id', 'created_at', 'text', 'liberal_sentiment', 'conservative_sentiment']]\n",
    "refined_df['created_at'] = pd.to_datetime(refined_df['created_at'])\n",
    "refined_df = refined_df.sort_values(by=['author_id', 'created_at'], ascending=[True, False])\n",
    "refined_df = refined_df.drop_duplicates(subset=['author_id'], keep='first')\n",
    "refined_df = refined_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0f0556e-572a-4967-a34e-656ce0502113",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# New (abfss://, delta format)\n",
    "output_path = f\"abfss://sentimentresults@{storage_account_name}.dfs.core.windows.net/sentiment_results_refined/\"\n",
    "refined_spark_df = spark.createDataFrame(refined_df)\n",
    "refined_spark_df.write.format(\"delta\").mode(\"overwrite\").save(output_path)\n",
    "print(\"Refined Sentiment Results saved as Delta Table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94bd87d9-23d9-468b-9302-6b671eb1575a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE DATABASE IF NOT EXISTS sentiment_db\n",
    "COMMENT \"Database for Canadian Twitter Sentiment Analysis\";\n",
    "USE sentiment_db;\n",
    "DROP TABLE IF EXISTS sentiment_results;\n",
    "CREATE TABLE IF NOT EXISTS sentiment_results\n",
    "USING DELTA\n",
    "LOCATION 'abfss://sentimentresults@twdrprdcacentral.dfs.core.windows.net/sentiment_results_refined/';"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5946388281019455,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) Sentiment_Analysis_Twitter",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}